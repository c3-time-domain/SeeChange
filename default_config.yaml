overrides:
  - local_overrides.yaml
augments:
  - local_augments.yaml

path:
  data_root: null
  data_temp: null

db:
  engine: postgresql
  user: postgres
  password: fragile
  host: localhost
  port: 5432
  database: seechange

storage:
  images:
    # can choose hdf5 as well, but this is not yet implemented
    format: fits
    # should Image object save the weights/flags/etc in a single file with the image data?
    single_file: false
    # The convention for building filenames for images
    # Use any of the following: short_name, date, time, section_id, filter, ra, dec, prov_id
    # Can also use section_id_int if the section_id is always an integer
    # Can also use ra_int and ra_frac to get the integer number before/after the decimal point
    # (the same can be done for dec). Also use ra_int_h to get the number in hours.
    # to get the declination with "p" or "m" replacing the sign, use dec_int_pm.
    # The string given here is fed into the python format() function
    # so you can use e.g., {ra_int:03d} to get a 3 digit zero padded right ascension.
    # The name convention can also include subfolders (e.g., using {ra_int}/...).
    # The minimal set of fields to make the filenames unique include:
    # inst_name (short instrument name), date, time, section_id, prov_hash
    # (in this example, the first six characters of the provenance unique hash)
    name_convention: "{ra_int:03d}/{inst_name}_{date}_{time}_{section_id}_{filter}_{im_type}_{prov_hash:.6s}"


# ======================================================================
# Archive:
#
# Set to null if there is no archive; otherwise, a dict
# Subfields:
#   url: the URL of the archive server, or null if archive is on the filesystem
#   verify_cert: boolean, should we verify the SSL cert of the archive server
#   path_base: the base of the collection on the archive server (a string unique to this dataset)
#   read_dir: the directory to read from if the archive is on the local filesystem, or null
#   write_dir: the directory to write to if the archive is on the local filesystem, or null

archive: null

# ======================================================================
# Gaia DR3 server
#
# There are two ways we can get it : through the server defined in the
#  submodule extern/nersc-desi-gaia-dr3-server, and via NOIRLab
#  using their queryClient.
# Set use_server to True to use the custom one
# Set use_datalab to True to use NOIRLab datalab.  This will
#   be ignored if use_server is True
# Set fallback_datalab to True to try to use NOIRLab datalab
#   if the custom server doesn't return after five tries.
# server_url is the server where the custom server runs

catalog_gaiadr3:
  use_server: True
  use_datalab: False
  fallback_datalab: True
  server_url: https://ls4-gaia-dr3.lbl.gov
  server_timeout_sec: 5.


# ======================================================================
# Pipeline components
#
# For documentation on the parameters, see the Parameters subclass
# in the file that defines each part of the pipeline

pipeline: {}

preprocessing:
  use_sky_subtraction: False
  steps_required: [ 'overscan', 'linearity', 'flat', 'fringe' ]

extraction:
  sources:
    measure_psf: true
    threshold: 3.0
    method: sextractor

  wcs:
    cross_match_catalog: gaia_dr3
    solution_method: scamp
    max_catalog_mag: [20.0]
    mag_range_catalog: 4.0
    min_catalog_stars: 50
    max_sources_to_use: [2000, 1000, 500, 200]

  zp:
    cross_match_catalog: gaia_dr3
    max_catalog_mag: [20.0]
    mag_range_catalog: 4.0
    min_catalog_stars: 50

subtraction:
  method: zogy
  alignment:
    method: swarp
    to_index: new

detection:
  subtraction: true
  method: filter  # when using ZOGY subtraction, detection method must be "filter"!
  threshold: 5.0

cutting:
  cutout_size: 25

measuring:
  annulus_radii: [10, 15]
  annulus_units: pixels
  chosen_aperture: 0
  analytical_cuts: ['negatives', 'bad pixels', 'offsets', 'filter bank']
  outlier_sigma: 3.0
  bad_pixel_radius: 3.0
  bad_pixel_exclude: []
  streak_filter_angle_step: 5.0
  width_filter_multipliers: [0.25, 2.0, 5.0, 10.0]
  association_radius: 2.0
  thresholds:
    negatives: 0.3
    bad pixels: 1
    offsets: 5.0
    filter bank: 1
  deletion_thresholds:
    negatives: 0.3
    bad pixels: 1
    offsets: 5.0
    filter bank: 1


# Specific configuration for specific instruments.
# Instruments should override the two defaults from
# instrument_default; they may add additional
# configuration that their code needs.

instrument_default:
  calibratorset: nightly
  flattype: sky

# Config for astromatic utilities (sextractor, scamp, swarp, psfex)
astromatic:
  # An absolute path to where astromatic config files are
  config_dir: null
  # A path relative to models/base/CODE_ROOT where the astromatic
  # config files are. Ignored if config_dir is not null
  config_subdir: data/astromatic_config

coaddition:
  coaddition:
    method: zogy
    noise_estimator: sep
    flag_fwhm_factor: 1.0
    alignment:
      method: swarp
      to_index: last
    inpainting:
      multi_image_method: median
      feather_width: 2
      rescale_method: median
      single_image_method: biharmonic
      ignore_flags: 0
  # The following are used to override the regular "extraction" parameters
  extraction:
    sources:
      measure_psf: true
      threshold: 3.0
      method: sextractor
    # The following are used to override the regular astrometric calibration parameters
    wcs:
      cross_match_catalog: gaia_dr3
      solution_method: scamp
      max_catalog_mag: [22.0]
      mag_range_catalog: 6.0
      min_catalog_stars: 50
    # The following are used to override the regular photometric calibration parameters
    zp:
      cross_match_catalog: gaia_dr3
      max_catalog_mag: [22.0]
      mag_range_catalog: 6.0
      min_catalog_stars: 50


# DECam

# For the observatory-supplied calibrations, NOIRLab distributes them on
# a Google Drive, which is a nightmare to try to download
# programmatically.  What's more, they come in ginormous tar files,
# which are slow to process; especially for tests, where we just want to
# do a couple of chips, it's not worth the time.  So, I've untarred the
# files on the NERSC web portal to allow them to be grabbed
# individually.  These can be found on Perlmutter at
# /global/cfs/dirs/m2218/www/decam_calibration_files

DECam:
  calibratorset: externally_supplied
  flattype: externally_supplied
  calibfiles:
    mjd: 56876
    urlbase: https://portal.nersc.gov/cfs/m4616/decam_calibration_files/
    linearity: DECamMasterCal_56475/linearity/linearity_table_v0.4.fits
    fringebase: DECamMasterCal_56876/fringecor/DECam_Master_20131115v1
    flatbase: DECamMasterCal_56876/starflat/DECam_Master_20130829v3
    bpmbase: DECamMasterCal_56876/bpm/DECam_Master_20140209v2_cd_
